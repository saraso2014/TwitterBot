{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MDPXp5-X80r"
   },
   "source": [
    "# Scraper for Twitter using GetOldTweets3\n",
    "\n",
    "Package: https://github.com/Mottl/GetOldTweets3\n",
    "\n",
    "### Notebook Author: Martin Beck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vp7x7kWeYABh",
    "outputId": "af1a20c2-2262-47f8-e27f-90076bd7860b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GetOldTweets3 in /Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages (0.0.11)\n",
      "Requirement already satisfied: pyquery>=1.2.10 in /Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages (from GetOldTweets3) (1.4.1)\n",
      "Requirement already satisfied: lxml>=3.5.0 in /Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages (from GetOldTweets3) (4.5.0)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n",
      "\u001b[31mERROR: Error checking for conflicts.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3012, in _parsed_pkg_info\n",
      "    return self._pkg_info\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _pkg_info\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/commands/install.py\", line 517, in _warn_about_conflicts\n",
      "    package_set, _dep_info = check_install_conflicts(to_install)\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/operations/check.py\", line 114, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/operations/check.py\", line 53, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3032, in _compute_dependencies\n",
      "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3014, in _parsed_pkg_info\n",
      "    metadata = self.get_metadata(self.PKG_INFO)\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1420, in get_metadata\n",
      "    value = self._get(path)\n",
      "  File \"/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1616, in _get\n",
      "    with open(path, 'rb') as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/sarasoueidan/opt/anaconda3/lib/python3.7/site-packages/pandas-1.0.3.dist-info/METADATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Pip install GetOldTweets3 if you don't already have the package\n",
    "!pip install GetOldTweets3\n",
    "\n",
    "# Imports\n",
    "import GetOldTweets3 as got\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "he3accCbyaWG"
   },
   "source": [
    "## Query by Username\n",
    "Creation of queries using GetOldTweets3\n",
    "\n",
    "Function is focused on completing the query then providing a CSV file of that query using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54rhT5wfZVXD"
   },
   "outputs": [],
   "source": [
    "# Function the pulls tweets from a specific username and turns to csv file\n",
    "\n",
    "# Parameters: (list of twitter usernames), (max number of most recent tweets to pull from)\n",
    "def username_tweets_to_csv(username, count):\n",
    "    # Creation of query object\n",
    "    tweetCriteria = got.manager.TweetCriteria().setUsername(username)\\\n",
    "                                            .setMaxTweets(count)\n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    # Creating list of chosen tweet data\n",
    "    user_tweets = [[tweet.date, tweet.text] for tweet in tweets]\n",
    "\n",
    "    # Creation of dataframe from tweets list\n",
    "    tweets_df = pd.DataFrame(user_tweets, columns = ['Datetime', 'Text'])\n",
    "\n",
    "    # Converting dataframe to CSV\n",
    "    tweets_df.to_csv('{}-{}k-tweets.csv'.format(username, int(count/1000)), sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7r4McYgyoQy"
   },
   "source": [
    "## Query by Text Search\n",
    "Function is focused on completing the query then providing a CSV file of that query using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSjpix_9A5e6"
   },
   "outputs": [],
   "source": [
    "# Function that pulls tweets based on a general search query and turns to csv file\n",
    "\n",
    "# Parameters: (text query you want to search), (max number of most recent tweets to pull from)\n",
    "def text_query_to_csv(query, count,start_date,end_date):\n",
    "    # Creation of query object\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(query)\\\n",
    "                                               .setMaxTweets(count)\\\n",
    "                                               .setSince(start_date)\\\n",
    "                                               .setUntil(end_date)\\\n",
    "                                             #  .setNear(city)\\\n",
    "                                            #  .setWithin(radius)\n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    # Creating list of chosen tweet data\n",
    "    text_tweets = [[tweet.date, tweet.text] for tweet in tweets]\n",
    "\n",
    "    # Creation of dataframe from tweets\n",
    "    tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Text'])\n",
    "\n",
    "    # Converting tweets dataframe to csv file\n",
    "    tweets_df.to_csv('{}-{}k-tweets.csv'.format(query, int(count/1000)), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'power outage'\n",
    "count = 10000\n",
    "since = '2019-10-16'\n",
    "until = '2019-10-20'\n",
    "city = 'Boston'\n",
    "radius = '15mi'\n",
    "\n",
    "text_query_to_csv(query,count,since,until)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWyvF9CQykPz"
   },
   "source": [
    "## Query Function Calls\n",
    "Putting it all together and using functions created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQfm6LdhZafM"
   },
   "outputs": [],
   "source": [
    "# Input username(s) to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "username = 'jack'\n",
    "count = 5000\n",
    "\n",
    "# Calling function to turn username's past x amount of tweets into a CSV file\n",
    "username_tweets_to_csv(username, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Locations of Interest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc = '40.730610,-73.935242,15mi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3xppry-1XM0"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tweet' object has no attribute 'place'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e2480198d135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Calling function to query X amount of relevant tweets and create a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtext_query_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-cc3950e3d02a>\u001b[0m in \u001b[0;36mtext_query_to_csv\u001b[0;34m(text_query, count)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Creating list of chosen tweet data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtext_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Creation of dataframe from tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-cc3950e3d02a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Creating list of chosen tweet data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtext_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Creation of dataframe from tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tweet' object has no attribute 'place'"
     ]
    }
   ],
   "source": [
    "# Input search query to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "text_query = '#poweroutage'\n",
    "count = 5000\n",
    "\n",
    "# Calling function to query X amount of relevant tweets and create a CSV file\n",
    "text_query_to_csv(text_query, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GetOldTweets3 Twitter Scraper",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
