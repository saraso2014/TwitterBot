{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xh92xbMkLy28"
   },
   "source": [
    "# Scraper for Twitter using Tweepy\n",
    "\n",
    "Package Github: https://github.com/tweepy/tweepy\n",
    "\n",
    "Package Documentation: https://tweepy.readthedocs.io/en/latest/\n",
    "\n",
    "### Notebook Author: Martin Beck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "id": "90OU2SDJL2Q9",
    "outputId": "89d239d4-dc97-43c7-fff0-cbbe793bf094"
   },
   "outputs": [],
   "source": [
    "# Pip install Tweepy if you don't already have the package\n",
    "# !pip install tweepy\n",
    "\n",
    "# Imports\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5q3dtxauP0KR"
   },
   "source": [
    "## Credentials and Authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NcOQy9XM5hR"
   },
   "outputs": [],
   "source": [
    "# Credentials\n",
    "\n",
    "consumer_key = \"XXXXXXXXX\"\n",
    "consumer_secret = \"XXXXXXXXX\"\n",
    "access_token = \"XXXXXXXXX\"\n",
    "access_token_secret = \"XXXXXXXXX\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvBbNQXgM3QI"
   },
   "source": [
    "## Query by Username\n",
    "Creation of queries using Tweepy API\n",
    "\n",
    "Function is focused on completing the query then providing a CSV file of that query using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fguMqU2ifc5h"
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "def username_tweets_to_csv(username,count):\n",
    "    try: \n",
    "    # Pulling individual tweets from query\n",
    "        for tweet in api.user_timeline(id=username, count=count):\n",
    "\n",
    "            # Adding to list that contains all tweets\n",
    "            tweets.append((tweet.created_at,tweet.id,tweet.text))\n",
    "\n",
    "            # Creation of dataframe from tweets list\n",
    "            tweetsdf = pd.DataFrame(tweets,columns=['Datetime', 'Tweet Id', 'Text'])\n",
    "\n",
    "            # Converting dataframe to CSV\n",
    "            tweetsdf.to_csv('{}-tweets.csv'.format(username)) \n",
    "\n",
    "    except BaseException as e:\n",
    "          print('failed on_status,',str(e))\n",
    "          time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jFe9EonmM6u9"
   },
   "source": [
    "## Query by Text Search\n",
    "Function is focused on completing the query then providing a CSV file of that query using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1hOeCFq6M83k"
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "def text_query_to_csv(text_query,count):\n",
    "    try:\n",
    "    # Pulling individual tweets from query\n",
    "        for tweet in api.search(q=text_query, count=count):\n",
    "\n",
    "          # Adding to list that contains all tweets\n",
    "          tweets.append((tweet.created_at,tweet.id,tweet.text))\n",
    "\n",
    "          # Creation of dataframe from tweets list\n",
    "          tweetsdf = pd.DataFrame(tweets,columns=['Datetime', 'Tweet Id', 'Text'])\n",
    "\n",
    "          # Converting dataframe to CSV\n",
    "          tweetsdf.to_csv('{}-tweets.csv'.format(text_query)) \n",
    "\n",
    "    except BaseException as e:\n",
    "        print('failed on_status,',str(e))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJcKa7Wrk_e2"
   },
   "source": [
    "## Query Function Calls\n",
    "Putting it all together and using functions created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GT3fFlfhleIN"
   },
   "outputs": [],
   "source": [
    "# Input username to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "username = 'jack'\n",
    "count = 150\n",
    "\n",
    "# Calling function to turn username's past X amount of tweets into a CSV file\n",
    "username_tweets_to_csv(username, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgK3Am48leWF"
   },
   "outputs": [],
   "source": [
    "# Input search query to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "text_query = 'USA Election 2020'\n",
    "count = 150\n",
    "\n",
    "# Calling function to query X amount of relevant tweets and create a CSV file\n",
    "text_query_to_csv(text_query, count)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tweepy Twitter Scraper",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
